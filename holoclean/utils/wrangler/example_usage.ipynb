{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick walkthrough of wrangling a df in HoloClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = spark.read.csv(\"../../../datasets/food/food_input_holo.csv\", header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the large number of variants on 'Chicago' in this dataset. Our wrangler attempts to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'GLENCOE', u'LAKE ZURICH', u'Maywood', u'EAST HAZEL CREST', u'SCHAUMBURG', u'SCHILLER PARK', u'chicago', u'BURNHAM', u'CHicago', u'BLOOMINGDALE', u'WORTH', u'CHICAGOI', u'INACTIVE', u'DES PLAINES', u'ELK GROVE VILLAGE', u'STREAMWOOD', u'EVERGREEN PARK', u'CALUMET CITY', u'OAK PARK', None, u'BRIDEVIEW', u'MAYWOOD', u'BERWYN', u'NILES NILES', u'BEDFORD PARK', u'OOLYMPIA FIELDS', u'CHCICAGO', u'Chicago', u'JUSTICE', u'ELMHURST', u'CHARLES A HAYES', u'BANNOCKBURNDEERFIELD', u'CHICAGO', u'CICERO', u'CCHICAGO', u'TINLEY PARK', u'CHICAGO HEIGHTS', u'EVANSTON', u'Norridge', u'OAK LAWN', u'CHICAGOCHICAGO', u'CHCHICAGO', u'OLYMPIA FIELDS', u'LOMBARD', u'alsip', u'COUNTRY CLUB HILLS', u'FRANKFORT', u'CHESTNUT STREET', u'BOLINGBROOK', u'NAPERVILLE', u'ALSIP', u'SKOKIE', u'BLUE ISLAND', u'SUMMIT', u'BROADVIEW', u'WESTMONT']\n"
     ]
    }
   ],
   "source": [
    "print [i.city for i in data.select('city').distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrangler import Wrangler\n",
    "\n",
    "wrangler = Wrangler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "from transform_functions import lowercase, trim\n",
    "\n",
    "functions = [lowercase, trim]\n",
    "columns = [\"city\", \"dbaname\"]\n",
    "\n",
    "transformer = Transformer(functions, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangler.add_transformer(transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our wrangler by default uses levenshtein's distance but it can take any distance function for comparing strings.\n",
    "\n",
    "The only trick is you must specify the threshold at which to stop clustering. For example, levenshtein's distance uses a default threshold of 3, so 'chicago' and 'checago' will be clustered but 'chicago' and 'cafcebo' will not. This threshold needs to be chosen depending on the distance function used and the known properties of the column's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from col_norm_info import ColNormInfo\n",
    "import distance\n",
    "\n",
    "cols = list()\n",
    "cols.append(ColNormInfo(\"city\"))\n",
    "cols.append(ColNormInfo(\"dbaname\", distance.jaccard, 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the column information, our normalizer takes the max number of distinct values that we will permit it to compare. Any more than that and the process becomes too time and space intensive so we simply do not normalize any column that fails that condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normalizer import Normalizer\n",
    "\n",
    "normalizer = Normalizer(cols, max_distinct=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangler.add_normalizer(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangled_df = wrangler.wrangle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all values have been simplified, and various chicago typos have been combined into just 'chicago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'charles a hayes', u'maywood', u'streamwood', u'broadview', u'bannockburndeerfield', u'chicago', u'summit', u'tinley park', u'calumet city', None, u'bolingbrook', u'worth', u'country club hills', u'burnham', u'blue island', u'evergreen park', u'niles niles', u'norridge', u'des plaines', u'chicago heights', u'bloomingdale', u'evanston', u'lombard', u'skokie', u'lake zurich', u'glencoe', u'frankfort', u'east hazel crest', u'westmont', u'schiller park', u'schaumburg', u'oak park', u'alsip', u'elmhurst', u'bedford park', u'inactive', u'chestnut street', u'elk grove village', u'berwyn', u'naperville', u'oolympia fields', u'justice', u'chicagochicago']\n"
     ]
    }
   ],
   "source": [
    "print [i.city for i in wrangled_df.select('city').distinct().collect()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
