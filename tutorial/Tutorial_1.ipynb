{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Session` manages a connection to the Postgres database automatically  and allows us to save intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first in our set of tutorials introduces the infrastructure of `HoloClean` and presents the initial steps needed to get your data interacting with `HoloClean`. We'll also discuss Denial Constraints, the primary source of information that `HoloClean` uses to perform repairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Holoclean: Data Loading and Denial Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup & Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without further ado, let's see some code! We begin by initializing `HoloClean` and `Session` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyas/anaconda3/envs/py27/lib/python2.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "\n",
    "holo =      HoloClean(\n",
    "            holoclean_path=\"..\",         # path to holoclean package\n",
    "            verbose=False,\n",
    "            # to limit possible values for training data\n",
    "            pruning_threshold1=0.1,\n",
    "            # to limit possible values for training data to less than k values\n",
    "            pruning_clean_breakoff=6,\n",
    "            # to limit possible values for dirty data (applied after\n",
    "            # Threshold 1)\n",
    "            pruning_threshold2=0,\n",
    "            # to limit possible values for dirty data to less than k values\n",
    "            pruning_dk_breakoff=6,\n",
    "            # learning parameters\n",
    "            learning_iterations=30,\n",
    "            learning_rate=0.001,\n",
    "            batch_size=5\n",
    "        )\n",
    "session = Session(holo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we ingest the hospital data we'd like to clean. This is a commonly used research dataset that we'll be using for all of our introductory tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Load Data: 12.2033860683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/hospital.csv\"\n",
    "\n",
    "data = session.load_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this time, we only support .csv files for our data format. \n",
    "\n",
    "The data is then loaded into the database and a representation is returned. `HoloClean` uses PySpark DataFrames as its internal data structure and so any PySpark operations can be used.\n",
    "\n",
    "For Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|        HospitalName|      City|\n",
      "+--------------------+----------+\n",
      "|CALLAHAN EYE FOUN...|BIRMINGHAM|\n",
      "|CALLAHAN EYE FOUN...|BIRMINGHAM|\n",
      "|CALLAHAN EYE FOUN...|BIRMINGHAM|\n",
      "|CALLAHAN EYE FOUN...|BIRMINGHxM|\n",
      "|CALLAHAN EYE FOUN...|BIRMINGHAM|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('HospitalName', 'City').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ProviderNumber: string (nullable = true)\n",
      " |-- HospitalName: string (nullable = true)\n",
      " |-- Address1: string (nullable = true)\n",
      " |-- Address2: string (nullable = true)\n",
      " |-- Address3: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- ZipCode: string (nullable = true)\n",
      " |-- CountyName: string (nullable = true)\n",
      " |-- PhoneNumber: string (nullable = true)\n",
      " |-- HospitalType: string (nullable = true)\n",
      " |-- HospitalOwner: string (nullable = true)\n",
      " |-- EmergencyService: string (nullable = true)\n",
      " |-- Condition: string (nullable = true)\n",
      " |-- MeasureCode: string (nullable = true)\n",
      " |-- MeasureName: string (nullable = true)\n",
      " |-- Score: string (nullable = true)\n",
      " |-- Sample: string (nullable = true)\n",
      " |-- Stateavg: string (nullable = true)\n",
      " |-- __ind: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the [Apache Spark website](https://spark.apache.org/docs/latest/sql-programming-guide.html) for a full guide through DataFrames and their functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Introduction to Denial Constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoloClean's goal is to clean your data, and the system is driven by a description of what clean data *should* be like. These are expressed in the form of a Denial Constraint, which is similar to a [functional dependency](https://en.wikipedia.org/wiki/Functional_dependency). However, functional dependencies express things that should hold for your data, a denial constraint expresses what clean data is not like.\n",
    "\n",
    "### An Example: The Hospital Dataset\n",
    "\n",
    "This tutorial will walk through one of the Denial Constraints used in the Hospital Dataset. The data has the following fields:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`\n",
    "index,\n",
    "ProviderNumber,\n",
    "HospitalName,\n",
    "Address1,\n",
    "Address2,\n",
    "Address3,\n",
    "City,\n",
    "State,\n",
    "ZipCode,\n",
    "CountyName,\n",
    "PhoneNumber,\n",
    "HospitalType,\n",
    "HospitalOwner,\n",
    "EmergencyService,\n",
    "Condition,\n",
    "MeasureCode,\n",
    "MeasureName,\n",
    "Score,\n",
    "Sample,\n",
    "Stateavg`\n",
    "\n",
    "\n",
    "And we know that there are some errors in our data. For example some people have mistyped the city name, and so we see results like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      City|ZipCode|\n",
      "+----------+-------+\n",
      "|BIRMINGHAM|  35233|\n",
      "|BIRMINGHAM|  35233|\n",
      "|BIRMINGHAM|  35233|\n",
      "|BIRMINGHxM|  35233|\n",
      "|BIRMINGHAM|  35233|\n",
      "|BIRMINGHAM|  35233|\n",
      "|BIRMINGHAM|  35233|\n",
      "|BIRMINGxAM|  35233|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFxELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "| SHEFFIELD|  35660|\n",
      "|    DOTHAN|  36302|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('City', 'ZipCode').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we have an issue with a city called `BIRMGINxAM`. However, we know that whenever the zip codes are the same, the city should be the same. In the language of functional dependencies we could write this as: for any records $t_1, t_2$\n",
    "\n",
    "$$t_1.ZipCode = t_2.ZipCode \\implies t_1.City = t_2.City$$\n",
    "\n",
    "However the HoloClean denial constraint will be.\n",
    "\n",
    "`t1&t2&EQ(t1.ZipCode,t2.ZipCode)&IQ(t1.City,t2.City)`\n",
    "\n",
    "Let's break down how this works:`t1&t2` specifies that two records will be involved in the error. `EQ(t1.ZipCode, t2.ZipCode)&IQ(t1.City, t2.City)` says that the records will have equal zip codes, but inequal cities. Now any pairs of records in the hospital dataset which make this true will be marked as potentially dirty.\n",
    "\n",
    "\n",
    "## Adding Denial Constraints to HoloClean\n",
    "There are multiple ways to add denial constraints to the system, the first is to load from a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t1&t2&EQ(t1.ZipCode,t2.ZipCode)&IQ(t1.City,t2.City)',\n",
       " 't1&t2&EQ(t1.ZipCode,t2.ZipCode)&IQ(t1.State,t2.State)',\n",
       " 't1&t2&EQ(t1.PhoneNumber,t2.PhoneNumber)&IQ(t1.ZipCode,t2.ZipCode)',\n",
       " 't1&t2&EQ(t1.PhoneNumber,t2.PhoneNumber)&IQ(t1.City,t2.City)',\n",
       " 't1&t2&EQ(t1.PhoneNumber,t2.PhoneNumber)&IQ(t1.State,t2.State)',\n",
       " 't1&t2&EQ(t1.ProviderNumber,t2.ProviderNumber)&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.Stateavg,t2.Stateavg)',\n",
       " 't1&t2&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.MeasureName,t2.MeasureName)',\n",
       " 't1&t2&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.Condition,t2.Condition)',\n",
       " 't1&t2&EQ(t1.State,t2.State)&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.Stateavg,t2.Stateavg)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load a set of denial contstraints\n",
    "dc_path = \"data/hospital_constraints.txt\"\n",
    "dcs = session.load_denial_constraints(dc_path)\n",
    "dcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding/Removing Constraints one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t1&t2&EQ(t1.ZipCode,t2.ZipCode)&IQ(t1.City,t2.City)',\n",
       " 't1&t2&EQ(t1.ZipCode,t2.ZipCode)&IQ(t1.State,t2.State)',\n",
       " 't1&t2&EQ(t1.PhoneNumber,t2.PhoneNumber)&IQ(t1.ZipCode,t2.ZipCode)',\n",
       " 't1&t2&EQ(t1.PhoneNumber,t2.PhoneNumber)&IQ(t1.City,t2.City)',\n",
       " 't1&t2&EQ(t1.PhoneNumber,t2.PhoneNumber)&IQ(t1.State,t2.State)',\n",
       " 't1&t2&EQ(t1.ProviderNumber,t2.ProviderNumber)&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.Stateavg,t2.Stateavg)',\n",
       " 't1&t2&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.MeasureName,t2.MeasureName)',\n",
       " 't1&t2&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.Condition,t2.Condition)',\n",
       " 't1&t2&EQ(t1.State,t2.State)&EQ(t1.MeasureCode,t2.MeasureCode)&IQ(t1.Stateavg,t2.Stateavg)',\n",
       " 't1&t2&EQ(t1.ZipCode,t2.ZipCode)&IQ(t1.Stateavg,t2.Stateavg)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcs = session.add_denial_constraint('t1&t2&EQ(t1.ZipCode,t2.ZipCode)&IQ(t1.Stateavg,t2.Stateavg)')\n",
    "dcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denial Constraint Operators\n",
    "\n",
    "If you want a thorough introduction to denial constraints, refer to the [HoloClean Paper](https://arxiv.org/pdf/1702.00820.pdf). For the brief introduction the logical operators available are:\n",
    "\n",
    "|Operator|Meaning|\n",
    "|--------|-----|\n",
    "|`EQ(x.y,z.w)`| `x.y==z.w` |\n",
    "|`IQ(x.y,z.w)`| `x.y != z.w` |\n",
    "|`GT(x.y, z.w)`| `x.y > z.y`|\n",
    "|`GTE(x.y, z.w)`| `x.y >= z.y`|\n",
    "|`LT(x.y, z.w)`| `x.y < z.y`|\n",
    "|`LT(x.y, z.w)`| `x.y <= z.y`|\n",
    "\n",
    "All denial constraints are of the form `t1&t2&<X>&<Y>&...`  where `<X>` and `<Y>` are logical operators mentioned above.\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "Denial Constraints are just one of HoloClean's error detectors that it uses for learning, if you'd like to write your own check out our [Error Detectors](Tutorial_3.ipynb) tutorial. If you want to learn about the next steps in the HoloClean pipeline, check out our [Complete Pipeline](Tutorial_2.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
