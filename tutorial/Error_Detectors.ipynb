{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Custom Error Detectors\n",
    "\n",
    "HoloClean learns to clean data by first splitting it into two categories `clean` and `dont_know` or `dk` for short. It then uses the `clean` set to learn a factor graph. We've provided one kind of error detector, the `DCErrorDetector` which uses Denial Constraints to make these splits. However, HoloClean accepts arbitrary splits through the `ErrorDetector` class.\n",
    "\n",
    "# A `hello world` Example\n",
    "The heart of an error detector is two functions, `get_noisy_cells` and `get_clean_cells`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleErrorDetector:\n",
    "    def __init__(self, spark_session):\n",
    "        self.spark_session = spark_session\n",
    "    \n",
    "    def get_noisy_cells(self, spark_data_frame):\n",
    "        spark_data_frame.createOrReplaceTempView(\"table1\")\n",
    "        query = \"SELECT index as ind \"\\\n",
    "                \"FROM table1 \"\\\n",
    "                \"WHERE \"\\\n",
    "                \"ZipCode LIKE '%x%'\"\n",
    "            \n",
    "        result = self.spark_session.sql(query)\n",
    "        attr_frame = self.spark_session.createDataFrame([['ZipCode']], ['attr'])\n",
    "        result = result.crossJoin(attr_frame)\n",
    "        return result\n",
    "                                              \n",
    "                                      \n",
    "        \n",
    "    \n",
    "    def get_clean_cells(self, spark_data_frame, noisy_cells_data_frame):\n",
    "        spark_data_frame.createOrReplaceTempView(\"table1\")\n",
    "        query = \"SELECT index as ind \"\\\n",
    "                \"FROM table1 \"\\\n",
    "                \"WHERE \"\\\n",
    "                \"ZipCode NOT LIKE '%x%'\"\n",
    "            \n",
    "        result = self.spark_session.sql(query)\n",
    "        attr_frame = self.spark_session.createDataFrame([['ZipCode']], ['attr'])\n",
    "        result = result.crossJoin(attr_frame)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshmcgrath/anaconda2/lib/python2.7/site-packages/sqlalchemy/dialects/mysql/base.py:1569: Warning: '@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\n",
      "  cursor.execute('SELECT @@tx_isolation')\n"
     ]
    }
   ],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "from holoclean.errordetection.errordetector import ErrorDetectors\n",
    "from holoclean.featurization.featurizer import SignalInit, SignalCooccur, SignalDC\n",
    "from holoclean.featurization.featurizer import Featurizer\n",
    "from holoclean.learning.softmax import SoftMax\n",
    "from holoclean.learning.accuracy import Accuracy\n",
    "import time\n",
    "\n",
    "holo_obj = HoloClean(mysql_driver = \"../holoclean/lib/mysql-connector-java-5.1.44-bin.jar\" )\n",
    "session = Session(\"Session\", holo_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for ingesting file: 4.73261594772\n",
      "\n",
      "Init table\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|index|ProviderNumber|        HospitalName|            Address1|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|    1|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    2|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    3|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    4|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    5|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    6|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    7|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    8|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    9|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   10|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   11|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   12|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   13|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   14|         1xx19|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   15|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   16|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   17|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   18|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   19|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   20|         10001|SOUTHEAST ALABAMA...|1108 ROSS CLARK C...|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = \"../datasets/hospital1k/hospital_dataset.csv\"\n",
    "\n",
    "denial_constraints = \"../datasets/hospital1k/hospital_constraints.txt\"\n",
    "\n",
    "ground_truth = \"../datasets/hospital1k/groundtruth.csv\"\n",
    "\n",
    "# Ingesting Dataset and Denial Constraints\n",
    "start_time = time.time()\n",
    "t0 = time.time()\n",
    "session.ingest_dataset(dataset)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "\n",
    "\n",
    "print 'time for ingesting file: ' + str(total) + '\\n'\n",
    "session.denial_constraints(denial_constraints)\n",
    "print 'Init table'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Init\", session.dataset)\n",
    "sql.select('index','ProviderNumber','HospitalName', 'Address1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#err_detector = ErrorDetectors(session.Denial_constraints, holo_obj.dataengine,\n",
    "                            # holo_obj.spark_session, session.dataset)\n",
    "err_2 = ErrorDetectors(session.Denial_constraints, holo_obj.dataengine,\n",
    "                             holo_obj.spark_session, session.dataset, SimpleErrorDetector(holo_obj.spark_session))\n",
    "session.add_error_detector(err_2)\n",
    "session.ds_detect_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"C_clean\", session.dataset)\n",
    "sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Init\", session.dataset)\n",
    "sql.select(\"ZipCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
