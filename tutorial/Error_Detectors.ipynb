{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Custom Error Detectors\n",
    "\n",
    "HoloClean learns to clean data by first splitting it into two categories `clean` and `dont_know` or `dk` for short. It then uses the `clean` set to learn a factor graph. We've provided one kind of error detector, the `DCErrorDetector` which uses Denial Constraints to make these splits. However, HoloClean accepts arbitrary splits through the `ErrorDetector` class.\n",
    "\n",
    "# A `hello world` Example\n",
    "The heart of an error detector is two functions, `get_noisy_cells` and `get_clean_cells`. We are using the hospital dataset from before. We know that some Zip Codes are formatted incorrectly, so we'll write an error detector thT gives HoloClean all the erroneous Zip Codes using some simple regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleErrorDetector:\n",
    "    def __init__(self, spark_session):\n",
    "        self.spark_session = spark_session\n",
    "    \n",
    "    def get_noisy_cells(self, spark_data_frame):\n",
    "        '''\n",
    "            well get a spark DataFrame Instance of our Data\n",
    "            and return a new DataFrame with the schema \n",
    "            |ind|attr|\n",
    "            \n",
    "            where ind is the index of our data \n",
    "            and attr is the name of the column \n",
    "            or columns we believe are dirty\n",
    "        '''\n",
    "    \n",
    "        spark_data_frame.createOrReplaceTempView(\"table1\")\n",
    "        query = \"SELECT index as ind \"\\\n",
    "                \"FROM table1 \"\\\n",
    "                \"WHERE \"\\\n",
    "                \"ZipCode NOT RLIKE '[0-9]{5}'\"\n",
    "            \n",
    "        result = self.spark_session.sql(query)\n",
    "        attr_frame = self.spark_session.createDataFrame([['ZipCode']], ['attr'])\n",
    "        result = result.crossJoin(attr_frame)\n",
    "        return result\n",
    "                                              \n",
    "                                      \n",
    "        \n",
    "    \n",
    "    def get_clean_cells(self, spark_data_frame, noisy_cells_data_frame):\n",
    "        '''\n",
    "            The same as before, but now we'll get \n",
    "            reference noisy data in case we need it\n",
    "        '''\n",
    "        spark_data_frame.createOrReplaceTempView(\"table1\")\n",
    "        query = \"SELECT index as ind \"\\\n",
    "                \"FROM table1 \"\\\n",
    "                \"WHERE \"\\\n",
    "                \"ZipCode RLIKE '[0-9]{5}'\"\n",
    "            \n",
    "        result = self.spark_session.sql(query)\n",
    "        attr_frame = self.spark_session.createDataFrame([['ZipCode']], ['attr'])\n",
    "        result = result.crossJoin(attr_frame)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll start up HoloClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshmcgrath/anaconda2/lib/python2.7/site-packages/sqlalchemy/dialects/mysql/base.py:1569: Warning: '@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\n",
      "  cursor.execute('SELECT @@tx_isolation')\n"
     ]
    }
   ],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "from holoclean.errordetection.errordetector import ErrorDetectors\n",
    "from holoclean.featurization.featurizer import SignalInit, SignalCooccur, SignalDC\n",
    "from holoclean.featurization.featurizer import Featurizer\n",
    "from holoclean.learning.softmax import SoftMax\n",
    "from holoclean.learning.accuracy import Accuracy\n",
    "\n",
    "\n",
    "holo_obj = HoloClean(mysql_driver = \"../holoclean/lib/mysql-connector-java-5.1.44-bin.jar\" )\n",
    "session = Session(\"Session\", holo_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And ingest the dataset\n",
    "\n",
    "You can review what's happening here in our [Getting Started](#) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+--------------------+--------------------+\n",
      "|index|ProviderNumber|        HospitalName|            Address1|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|    1|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    2|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    3|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    4|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    5|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    6|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    7|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    8|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    9|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   10|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   11|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   12|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   13|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   14|         1xx19|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   15|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   16|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   17|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   18|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   19|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   20|         10001|SOUTHEAST ALABAMA...|1108 ROSS CLARK C...|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = \"../datasets/hospital1k/hospital_dataset.csv\"\n",
    "\n",
    "denial_constraints = \"../datasets/hospital1k/hospital_constraints.txt\"\n",
    "\n",
    "ground_truth = \"../datasets/hospital1k/groundtruth.csv\"\n",
    "\n",
    "# Ingesting Dataset and Denial Constraints\n",
    "\n",
    "session.ingest_dataset(dataset)\n",
    "\n",
    "\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Init\", session.dataset)\n",
    "sql.select('index','ProviderNumber','HospitalName', 'Address1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Your Error Detector to HoloClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    We instantiate an ErrorDetector class,\n",
    "    and give it an instance of our\n",
    "    SimpleErrorDetector Object\n",
    "'''\n",
    "err = ErrorDetectors(SimpleErrorDetector(holo_obj.spark_session))\n",
    "session.add_error_detector(err)\n",
    "#run error detection\n",
    "session.ds_detect_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the results\n",
    "\n",
    "The following table will give us all records which are believed to be erroneous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|ind|   attr|\n",
      "+---+-------+\n",
      "| 45|ZipCode|\n",
      "| 64|ZipCode|\n",
      "| 71|ZipCode|\n",
      "| 94|ZipCode|\n",
      "|138|ZipCode|\n",
      "|140|ZipCode|\n",
      "|150|ZipCode|\n",
      "|158|ZipCode|\n",
      "|197|ZipCode|\n",
      "|233|ZipCode|\n",
      "|268|ZipCode|\n",
      "|284|ZipCode|\n",
      "|291|ZipCode|\n",
      "|326|ZipCode|\n",
      "|333|ZipCode|\n",
      "|341|ZipCode|\n",
      "|367|ZipCode|\n",
      "|376|ZipCode|\n",
      "|407|ZipCode|\n",
      "|421|ZipCode|\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"C_dk\", session.dataset)\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we view the original dataset, viewing index 45 will confirm our suspicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|index|ZipCode|\n",
      "+-----+-------+\n",
      "|   45|  x5957|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Init\", session.dataset)\n",
    "sql.filter(sql.index == 45).select([\"index\",\"ZipCode\"]).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
