{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noisy and erroneous data is a major bottleneck in analytics. Data cleaning and repairing account for about 60% of the work of data scientists. To address this bottleneck, we recently introduced HoloClean, a semi-automated data repairing framework that relies on statistical learning and inference to repair errors in structured data. In HoloClean, we build upon the paradigm of weak supervision and demonstrate how to leverage diverse signals, including user-defined heuristic rules (such as generalized data integrity constraints) and external dictionaries, to repair erroneous data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, we walk through the process of implementing Holoclean, by creating a simple end-to-end example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import all the module from Holoclean that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "from holoclean.errordetection.errordetector import ErrorDetectors\n",
    "from holoclean.featurization.featurizer import SignalInit, SignalCooccur, SignalDC\n",
    "from holoclean.featurization.featurizer import Featurizer\n",
    "from holoclean.learning.softmax import SoftMax\n",
    "from holoclean.learning.accuracy import Accuracy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Initialization\n",
    "In this part, we create the Holoclean and Session object that we will use for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "holo_obj = HoloClean(mysql_driver = \"../holoclean/lib/mysql-connector-java-5.1.44-bin.jar\" )\n",
    "session = Session(\"Session\", holo_obj)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input and DC from file\n",
    "Test data and the Denial Constraints will be read using the Session's ingestor.\n",
    "After ingesting the test data will be loaded into MySQL tables along with entries in the a metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for ingesting file: 4.78640913963\n",
      "\n",
      "Init table\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|index|ProviderNumber|        HospitalName|            Address1|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|    1|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    2|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    3|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    4|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    5|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    6|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    7|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    8|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    9|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   10|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   11|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   12|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   13|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   14|         1xx19|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   15|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   16|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   17|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   18|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   19|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   20|         10001|SOUTHEAST ALABAMA...|1108 ROSS CLARK C...|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = \"../datasets/hospital1k/hospital_dataset.csv\"\n",
    "\n",
    "denial_constraints = \"../datasets/hospital1k/hospital_constraints.txt\"\n",
    "\n",
    "ground_truth = \"../datasets/hospital1k/groundtruth.csv\"\n",
    "\n",
    "# Ingesting Dataset and Denial Constraints\n",
    "start_time = time.time()\n",
    "t0 = time.time()\n",
    "session.ingest_dataset(dataset)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "\n",
    "\n",
    "print 'time for ingesting file: ' + str(total) + '\\n'\n",
    "session.denial_constraints(denial_constraints)\n",
    "print 'Init table'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Init\", session.dataset)\n",
    "sql.select('index','ProviderNumber','HospitalName', 'Address1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection\n",
    "In this part, we create the error detection. The output of this part is the C_dk table that contains all the noisy cells and the C_Clean table that contains the clean cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denial Constraint Queries: \n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.ZipCode=table2.ZipCode AND table1.City<>table2.City)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.ZipCode=table2.ZipCode AND table1.State<>table2.State)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.PhoneNumber=table2.PhoneNumber AND table1.ZipCode<>table2.ZipCode)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.PhoneNumber=table2.PhoneNumber AND table1.City<>table2.City)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.PhoneNumber=table2.PhoneNumber AND table1.State<>table2.State)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.ProviderNumber=table2.ProviderNumber AND table1.MeasureCode=table2.MeasureCode AND table1.Stateavg<>table2.Stateavg)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.MeasureCode=table2.MeasureCode AND table1.MeasureName<>table2.MeasureName)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.MeasureCode=table2.MeasureCode AND table1.Condition<>table2.Condition)\n",
      "SELECT table1.index as ind,table2.index as indexT2 FROM df table1,df table2 WHERE (table1.State=table2.State AND table1.MeasureCode=table2.MeasureCode AND table1.Stateavg<>table2.Stateavg)\n",
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 38068)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jordan/anaconda2/lib/python2.7/SocketServer.py\", line 290, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/home/jordan/anaconda2/lib/python2.7/SocketServer.py\", line 318, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/home/jordan/anaconda2/lib/python2.7/SocketServer.py\", line 331, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/home/jordan/anaconda2/lib/python2.7/SocketServer.py\", line 652, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/jordan/anaconda2/lib/python2.7/site-packages/pyspark/accumulators.py\", line 235, in handle\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/jordan/anaconda2/lib/python2.7/site-packages/pyspark/serializers.py\", line 581, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o572.jdbc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-543b5c8e240e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                              holo_obj.spark_session, session.dataset)\n\u001b[1;32m      4\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_error_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_detector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_detect_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jordan/Code/HoloClean-v0.01/holoclean/holoclean.pyc\u001b[0m in \u001b[0;36mds_detect_errors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         self.holo_env.dataengine.add_db_table(\n\u001b[0;32m--> 344\u001b[0;31m             'C_dk', intersect_dk_cells, self.dataset)\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholo_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error detection is finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0munion_clean_cells\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jordan/Code/HoloClean-v0.01/holoclean/dataengine.pyc\u001b[0m in \u001b[0;36madd_db_table\u001b[0;34m(self, table_name, spark_dataframe, dataset, append)\u001b[0m\n\u001b[1;32m    236\u001b[0m         specific_table_name = self._add_info_to_meta(\n\u001b[1;32m    237\u001b[0m             table_name, schema, dataset)\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataframe_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecific_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mingest_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jordan/Code/HoloClean-v0.01/holoclean/dataengine.pyc\u001b[0m in \u001b[0;36m_dataframe_to_table\u001b[0;34m(self, spec_table_name, dataframe, append)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mspec_table_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 properties=dbProperties)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_query_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jordan/anaconda2/lib/python2.7/site-packages/pyspark/sql/readwriter.pyc\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jordan/anaconda2/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jordan/anaconda2/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jordan/anaconda2/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise Py4JError(\n\u001b[1;32m    326\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o572.jdbc"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "err_detector = ErrorDetectors(session.Denial_constraints, holo_obj.dataengine,\n",
    "                             holo_obj.spark_session, session.dataset)\n",
    "session.add_error_detector(err_detector)\n",
    "session.ds_detect_errors()\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "holo_obj.logger.info('error dectection time: '+str(total)+'\\n')\n",
    "print 'error dectection time: '+str(total)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Pruning\n",
    "In this part, we prune the domain. The output of this part is the possible_values tables that contains all the possible values for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "pruning_threshold = 0.5\n",
    "session.ds_domain_pruning(pruning_threshold)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "holo_obj.logger.info('domain pruning time: '+str(total)+'\\n')\n",
    "print 'domain pruning time: '+str(total)+'\\n'\n",
    "\n",
    "print 'Possible_values_clean'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Possible_values_clean\", session.dataset)\n",
    "sql.show()\n",
    "\n",
    "print 'Possible values dk'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Possible_values_dk\", session.dataset)\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we implement the featurization module of holoclean. We choose the signals that we want to use and the output of this part is the featurization table that contains the factors that we will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "initial_value_signal = SignalInit(session.Denial_constraints, holo_obj.dataengine,\n",
    "                              session.dataset)\n",
    "session.add_featurizer(initial_value_signal )\n",
    "statistics_signal = SignalCooccur(session.Denial_constraints, holo_obj.dataengine,\n",
    "                              session.dataset )\n",
    "session.add_featurizer(statistics_signal)\n",
    "dc_signal = SignalDC(session.Denial_constraints, holo_obj.dataengine, session.dataset,\n",
    "                 holo_obj.spark_session)\n",
    "session.add_featurizer(dc_signal)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print \"Feature Signal Time:\", total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the signals that we choose in the previous step. The output of this part is the featurization table that contains the factors that we will use in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "session.ds_featurize()\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1 - t0\n",
    "\n",
    "holo_obj.logger.info('featurization time: '+str(total)+'\\n')\n",
    "print 'featurization time: '+str(total)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Learning\n",
    "We create the X-tensor from the feature_clean table and run softmax on it, then we save results to MySQL and output the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "soft = SoftMax(holo_obj.dataengine, session.dataset, holo_obj.spark_session,\n",
    "                       session.X_training)\n",
    "\n",
    "soft.logreg()\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "\n",
    "print 'time for training model: '+str(total)+'\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use the new weight, to learn the probabilities for each value for the cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "session.ds_featurize(0)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print 'time for test featurization: ' + str(total) + '\\n'\n",
    "\n",
    "Y = soft.predict(soft.model, session.X_testing, soft.setupMask(0, session.N, session.L))\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print 'time for inference: ', total\n",
    "soft.save_prediction(Y)\n",
    "\n",
    "print 'Inferred values for dk cells'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Inferred_values\", session.dataset)\n",
    "sql.show()\n",
    "\n",
    "\n",
    "flattening = 0\n",
    "\n",
    "acc = Accuracy(holo_obj.dataengine, ground_truth, session.dataset,\n",
    "               holo_obj.spark_session)\n",
    "acc.accuracy_calculation(flattening)\n",
    "\n",
    "\n",
    "endtime = time.time()\n",
    "print 'total time: ', endtime - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
