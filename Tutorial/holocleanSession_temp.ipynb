{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test random varible evaluation\n",
    "\n",
    "For first step we create import the sufficient packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from holoclean import holocleansession , dataset , dataengine\n",
    "from holoclean.utils import domainpruning\n",
    "from holoclean.featurization import dcfeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = os.path.abspath(os.path.dirname('__file__'))\n",
    "path = os.path.join(my_path, \"../holoclean/mysql-connector-java-5.1.44-bin.jar\")\n",
    "holoclean_se=holocleansession.HolocleanSession(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Creating Dataset and dataengine and holocleansession \n",
    "In this part we create dataset for keep tracking the runnig step and dataengine for make connector to the database we try to ingest the 10 element csv file and after ingesting it returns df other wise we can read it from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n"
     ]
    }
   ],
   "source": [
    "ds=dataset.Dataset()  \n",
    "d=dataengine.Dataengine(\"metadb-config.txt\",'datadb-config.txt',ds,holoclean_se.return_sqlcontext())\n",
    "holoclean_se.set_dataengine(d)\n",
    "df=d.ingest_spark('10.csv',holoclean_se.returnspark_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create featurizere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcCode=['t1&t2&EQ(t1.city,t2.city)&EQ(t1.temp,t2.temp)&IQ(t1.tempType,t2.tempType)']\n",
    "dcf=dcfeaturizer.DCFeaturizer(df,dcCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alireza/anaconda2/lib/python2.7/site-packages/pyspark/sql/session.py:331: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+--------------------+------+\n",
      "|           rv|   assigned|                  dc|tup_id|\n",
      "+-------------+-----------+--------------------+------+\n",
      "|     t_1.temp|       -125|t1&t2&EQ(t1.city,...|     7|\n",
      "|     t_1.temp|       -148|t1&t2&EQ(t1.city,...|     2|\n",
      "|     t_2.temp|        -60|t1&t2&EQ(t1.city,...|     6|\n",
      "|     t_2.temp|        -75|t1&t2&EQ(t1.city,...|     1|\n",
      "| t_3.tempType|       TMAX|t1&t2&EQ(t1.city,...|     8|\n",
      "| t_3.tempType|       TMIN|t1&t2&EQ(t1.city,...|     8|\n",
      "|     t_4.temp|       -135|t1&t2&EQ(t1.city,...|    10|\n",
      "|     t_5.city|EZE00100082|t1&t2&EQ(t1.city,...|    10|\n",
      "| t_5.tempType|       TMAX|t1&t2&EQ(t1.city,...|    10|\n",
      "| t_5.tempType|       PRCP|t1&t2&EQ(t1.city,...|    10|\n",
      "|     t_5.temp|       -135|t1&t2&EQ(t1.city,...|    10|\n",
      "|     t_6.temp|       -125|t1&t2&EQ(t1.city,...|     7|\n",
      "|     t_6.temp|       -148|t1&t2&EQ(t1.city,...|     2|\n",
      "|     t_7.temp|        -60|t1&t2&EQ(t1.city,...|     6|\n",
      "|     t_7.temp|        -75|t1&t2&EQ(t1.city,...|     1|\n",
      "| t_8.tempType|       TMAX|t1&t2&EQ(t1.city,...|     3|\n",
      "| t_8.tempType|       TMIN|t1&t2&EQ(t1.city,...|     3|\n",
      "|     t_9.temp|       -135|t1&t2&EQ(t1.city,...|    10|\n",
      "|    t_10.city|EZE00100082|t1&t2&EQ(t1.city,...|     5|\n",
      "|t_10.tempType|       PRCP|t1&t2&EQ(t1.city,...|     5|\n",
      "+-------------+-----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dgf=dcf.pre_features(holoclean_se.returnspark_session())\n",
    "dgf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have just one dc in all value in dc column is same"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
