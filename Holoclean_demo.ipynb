{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Step-by-Step Guide to Holoclean example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noisy and erroneous data is a major bottleneck in analytics. Data cleaning and repairing account for about 60% of the work of data scientists. To address this bottleneck, we recently introduced HoloClean, a semi-automated data repairing framework that relies on statistical learning and inference to repair errors in structured data. In HoloClean, we build upon the paradigm of weak supervision and demonstrate how to leverage diverse signals, including user-defined heuristic rules (such as generalized data integrity constraints) and external dictionaries, to repair erroneous data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, we walk through the process of implementing Holoclean, by creating a simple end-to-end example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import all the module from Holoclean that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "from holoclean.errordetection.errordetector import ErrorDetectors\n",
    "from holoclean.featurization.featurizer import SignalInit, SignalCooccur, SignalDC\n",
    "from holoclean.learning.accuracy import Accuracy\n",
    "from time import time as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Initialization\n",
    "In this part, we create the Holoclean and Session object that we will use for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started :1517347649.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda/envs/python2.7/lib/python2.7/site-packages/sqlalchemy/dialects/mysql/base.py:1576: Warning: '@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\n",
      "  cursor.execute('SELECT @@tx_isolation')\n"
     ]
    }
   ],
   "source": [
    "        holo_obj = HoloClean()\n",
    "        session = Session(\"Session\", holo_obj) \n",
    "        print \"Testing started :\"+str(t())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input and DC from file\n",
    "Test data and the Denial Constraints will be read using the Session's ingestor.\n",
    "After ingesting the test data will be loaded into MySQL tables along with entries in the a metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init table\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|index|ProviderNumber|        HospitalName|            Address1|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|    1|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    2|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    3|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    4|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    5|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    6|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    7|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    8|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    9|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   10|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   11|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   12|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   13|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   14|         1xx19|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   15|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   16|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   17|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   18|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   19|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   20|         10001|SOUTHEAST ALABAMA...|1108 ROSS CLARK C...|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "ingest csv time: 8.58038711548\n",
      "\n",
      "read denial constraints time: 0.0063750743866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        fx = open('execution_time.txt', 'w')\n",
    "        list_time = []\n",
    "        start_time = t()\n",
    "        \n",
    "        session.ingest_dataset(\"test/inputDatabase.csv\")\n",
    "        #session.ingest_dataset(\"test/test.csv\")\n",
    "        d = t()-start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('ingest csv time: '+str(d)+'\\n')\n",
    "        fx.write('ingest csv time: '+str(d)+'\\n')\n",
    "        print 'Init table'\n",
    "        sql = holo_obj.dataengine.get_table_to_dataframe(\"Init\", session.dataset)\n",
    "        sql.select('index','ProviderNumber','HospitalName', 'Address1').show()\n",
    "        print 'ingest csv time: '+str(d)+'\\n'\n",
    "        \n",
    "        start_time = t()\n",
    "        \n",
    "        session.denial_constraints(\"test/inputConstraint.txt\")\n",
    "        #session.denial_constraints(\"test/dc1.txt\")\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('read denial constraints time: '+str(d)+'\\n')\n",
    "        fx.write('read denial constraints time: '+str(d)+'\\n')\n",
    "        print 'read denial constraints time: '+str(d)+'\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection\n",
    "In this part, we create the error detection. The output of this part is the C_dk table that contains all the noisy cells and the C_Clean table that contains the clean cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean table\n",
      "+---+----------------+\n",
      "|ind|            attr|\n",
      "+---+----------------+\n",
      "|106|        Address3|\n",
      "|132|   HospitalOwner|\n",
      "|106|EmergencyService|\n",
      "|107|    HospitalName|\n",
      "|126|      CountyName|\n",
      "|104|    HospitalType|\n",
      "| 10|        Address1|\n",
      "|163|  ProviderNumber|\n",
      "|165|        Stateavg|\n",
      "|111|        Address1|\n",
      "|110|    HospitalName|\n",
      "|110|  ProviderNumber|\n",
      "|147|        Address2|\n",
      "|167|   HospitalOwner|\n",
      "|140|           Score|\n",
      "|110|    HospitalType|\n",
      "|187|EmergencyService|\n",
      "|152|           Score|\n",
      "|109|    HospitalType|\n",
      "|156|      CountyName|\n",
      "+---+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Don't know table\n",
      "+---+-----------+\n",
      "|ind|       attr|\n",
      "+---+-----------+\n",
      "|897|       City|\n",
      "|658|       City|\n",
      "|952|       City|\n",
      "|677|    ZipCode|\n",
      "|228|    ZipCode|\n",
      "|466|    ZipCode|\n",
      "| 52|       City|\n",
      "|433|    ZipCode|\n",
      "|853|    ZipCode|\n",
      "|596|       City|\n",
      "|703|PhoneNumber|\n",
      "|533|    ZipCode|\n",
      "|219|    ZipCode|\n",
      "|206|       City|\n",
      "|199|       City|\n",
      "|643|    ZipCode|\n",
      "|941|    ZipCode|\n",
      "|377|    ZipCode|\n",
      "|772|PhoneNumber|\n",
      "|460|       City|\n",
      "+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "error dectection time: 212.851969957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        err_detector = ErrorDetectors(session.Denial_constraints, holo_obj.dataengine,\n",
    "                                      holo_obj.spark_session, session.dataset)\n",
    "        session.add_error_detector(err_detector)\n",
    "        session.ds_detect_errors()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('error dectection time: '+str(d)+'\\n')\n",
    "        fx.write('error dectection time: '+str(d)+'\\n')\n",
    "        \n",
    "        print 'Clean table'\n",
    "        sql = holo_obj.dataengine.get_table_to_dataframe(\"C_clean\", session.dataset)\n",
    "        sql.show()\n",
    "        print 'Don\\'t know table'\n",
    "        sql = holo_obj.dataengine.get_table_to_dataframe(\"C_dk\", session.dataset)\n",
    "        sql.show()\n",
    "        print 'error dectection time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Pruning\n",
    "In this part, we prune the domain. The output of this part is the possible_values tables that contains all the possible values for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Values table\n",
      "+---+-----------+-------------+--------+---------+\n",
      "|tid|  attr_name|     attr_val|observed|data_type|\n",
      "+---+-----------+-------------+--------+---------+\n",
      "|691|    ZipCode|        35233|       1|   String|\n",
      "|805|   Stateavg|     AL_AMI-3|       1|   String|\n",
      "|574|   Stateavg|      AL_HF-1|       1|   String|\n",
      "|456|       City|    SHEFFIELD|       1|   String|\n",
      "|232|       City|   FORT PAYNE|       1|   String|\n",
      "|113|   Stateavg|AL_SCIP-INF-1|       1|   String|\n",
      "|805|   Stateavg|      AL_HF-3|       0|   String|\n",
      "|691|PhoneNumber|   2059344011|       1|   String|\n",
      "|575|       City|       VALLEY|       1|   String|\n",
      "|456|       City|   BIRMINGHAM|       0|   String|\n",
      "|114|       City|          OPP|       1|   String|\n",
      "|232|      State|           AL|       1|   String|\n",
      "|806|       City|      GADSDEN|       1|   String|\n",
      "|114|      State|           AL|       1|   String|\n",
      "|232|    ZipCode|        35968|       1|   String|\n",
      "|575|      State|           AL|       1|   String|\n",
      "|806|      State|           AL|       1|   String|\n",
      "|114|    ZipCode|        36467|       1|   String|\n",
      "|348|       City|       DOTHAN|       1|   String|\n",
      "|456|      State|           AL|       1|   String|\n",
      "+---+-----------+-------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "domain pruning time: 9.43586587906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        pruning_threshold = 0.5\n",
    "        session.ds_domain_pruning(pruning_threshold)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('domain pruning time: '+str(d)+'\\n')\n",
    "        fx.write('domain pruning time: '+str(d)+'\\n')\n",
    "        \n",
    "        print 'Possible Values table'\n",
    "        sql = holo_obj.dataengine.get_table_to_dataframe(\"Possible_values\", session.dataset)\n",
    "        sql.show()\n",
    "        print 'domain pruning time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we implement the featurization module of holoclean. We choose the signals that we want to use and the output of this part is the featurization table that contains the factors that we will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Value Signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init signal time: 0.000649213790894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        start_time1 = t()\n",
    "        initial_value_signal = SignalInit(session.Denial_constraints, holo_obj.dataengine,\n",
    "                                          session.dataset)\n",
    "        session.add_featurizer(initial_value_signal)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('init signal time: '+str(d)+'\\n')\n",
    "        fx.write('init signal time: '+str(d)+'\\n')\n",
    "        print 'init signal time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurence Signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooccur signal time: 0.000582933425903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "   \n",
    "        statistics_signal = SignalCooccur(session.Denial_constraints, holo_obj.dataengine,\n",
    "                                          session.dataset)\n",
    "        session.add_featurizer(statistics_signal)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('cooccur signal time: '+str(d)+'\\n')\n",
    "        fx.write('cooccur signal time: '+str(d)+'\\n')\n",
    "        print 'cooccur signal time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dc signal time: 4.41074371338e-05\n",
      "\n",
      "dc featurize time: 0.000277042388916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('dc signal time: '+str(d)+'\\n')\n",
    "        fx.write('dc signal time: '+str(d)+'\\n')\n",
    "        print 'dc signal time: '+str(d)+'\\n'\n",
    "        start_time = t()\n",
    "        dc_signal = SignalDC(session.Denial_constraints, holo_obj.dataengine, session.dataset)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('dc featurize time: '+str(d)+'\\n')\n",
    "        fx.write('dc featurize time: '+str(d)+'\\n')\n",
    "        print 'dc featurize time: '+str(d)+'\\n'\n",
    "        session.add_featurizer(dc_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the signals that we choose in the previous steps. The output of this part is the featurization table that contains the factors that we will use in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding weight_id to feature table...\n",
      "adding weight_id to feature table is finished\n",
      "Feature table\n",
      "+---------+--------+---------+--------------------+--------------------+-------+---------+\n",
      "|var_index|rv_index|  rv_attr|        assigned_val|             feature|   TYPE|weight_id|\n",
      "+---------+--------+---------+--------------------+--------------------+-------+---------+\n",
      "|        1|       1|     City|          BIRMINGHAM|     Init=BIRMINGHAM|   init|       11|\n",
      "|        2|       1|     City|          BIRMINGHAM|ProviderNumber=10018|cooccur|      578|\n",
      "|        3|       1|     City|          BIRMINGHAM|HospitalName=CALL...|cooccur|      579|\n",
      "|        4|       1|     City|          BIRMINGHAM|Address1=1720 UNI...|cooccur|      580|\n",
      "|        5|       1|     City|          BIRMINGHAM|      Address2=Empty|cooccur|      571|\n",
      "|        6|       1|     City|          BIRMINGHAM|      Address3=Empty|cooccur|      572|\n",
      "|        7|       1|     City|          BIRMINGHAM|            State=AL|cooccur|      581|\n",
      "|        8|       1|     City|          BIRMINGHAM|CountyName=JEFFERSON|cooccur|      582|\n",
      "|        9|       1|     City|          BIRMINGHAM|HospitalType=Acut...|cooccur|      537|\n",
      "|       10|       1|     City|          BIRMINGHAM|HospitalOwner=Vol...|cooccur|      583|\n",
      "|       11|       1|     City|          BIRMINGHAM|EmergencyService=Yes|cooccur|      539|\n",
      "|       12|       1|     City|          BIRMINGHAM|         Score=Empty|cooccur|      584|\n",
      "|       13|       1|     City|          BIRMINGHAM|        Sample=Empty|cooccur|      585|\n",
      "|       14|       1|     City|          BIRMINGHAM|Stateavg=AL_SCIP-...|cooccur|      586|\n",
      "|       15|       1|     City|          BIRMINGHAM|4:table1.first_Zi...|     FD|     9078|\n",
      "|       16|       1|     City|          BIRMINGHAM|8:table1.first_Zi...|     FD|     9082|\n",
      "|       17|       1|     City|          BIRMINGHAM|691:table1.first_...|     FD|     9490|\n",
      "|       18|       1|     City|          BIRMINGHAM|4:table1.first_Ph...|     FD|    12643|\n",
      "|       19|       1|     City|          BIRMINGHAM|8:table1.first_Ph...|     FD|    12647|\n",
      "|       20|       1|Condition|Surgical Infectio...|Init=Surgical Inf...|   init|       21|\n",
      "+---------+--------+---------+--------------------+--------------------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "total featurization time: 551.745109081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        session.ds_featurize()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('total featurization time: '+str(d)+'\\n')\n",
    "        fx.write('total featurization time: '+str(d)+'\\n')\n",
    "        print 'Feature table'\n",
    "        sql = holo_obj.dataengine.get_table_to_dataframe(\"Feature\", session.dataset)\n",
    "        sql.show()\n",
    "        \n",
    "        print 'total featurization time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Learning\n",
    "In the learning phase, we create a wrapper for numbskull that we will use for the gibbs sampling. The output of this part is the new weight table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbskull is starting\n",
      "wrapper is starting\n",
      "wrapper is finished\n",
      "1\n",
      "numbskull is finished\n",
      "adding weight is finished is finished\n",
      "numbskull time: 224.518476963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        session._numskull()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('numbskull time: '+str(d)+'\\n')\n",
    "        fx.write('numbskull time: '+str(d)+'\\n')\n",
    "        print 'numbskull time: '+str(d)+'\\n'\n",
    "        start_time = t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use the new weight, to learn the probabilities for each value for the cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting repairs\n",
      "repairs are finished\n",
      "+-------+-------+--------+------------+-------------------+\n",
      "|rv_attr|rv_attr|rv_index|assigned_val|        probability|\n",
      "+-------+-------+--------+------------+-------------------+\n",
      "|   City|   City|       1|  BIRMINGHAM|                1.0|\n",
      "|   City|   City|      10|  BIRMINGHAM|0.26885085414689114|\n",
      "|   City|   City|      10|   SHEFFIELD| 0.7311491458531089|\n",
      "|   City|   City|     100|         OPP|                1.0|\n",
      "|   City|   City|    1000|     ONEONTA|                1.0|\n",
      "|   City|   City|     101|         OPP|                1.0|\n",
      "|   City|   City|     102|         OPP|                1.0|\n",
      "|   City|   City|     103|         OPP|                1.0|\n",
      "|   City|   City|     104|         OPP|                1.0|\n",
      "|   City|   City|     105|         OPP|                1.0|\n",
      "|   City|   City|     106|         OPP|                1.0|\n",
      "|   City|   City|     107|         OPP|                1.0|\n",
      "|   City|   City|     108|         OPP|                1.0|\n",
      "|   City|   City|     109|         OPP|                1.0|\n",
      "|   City|   City|      11|  BIRMINGHAM| 0.2690069634381427|\n",
      "|   City|   City|      11|   SHEFFxELD| 0.7309930365618573|\n",
      "|   City|   City|     110|         OPP|                1.0|\n",
      "|   City|   City|     111|         OPP|                1.0|\n",
      "|   City|   City|     112|         OPP|                1.0|\n",
      "|   City|   City|     113|         OPP|                1.0|\n",
      "+-------+-------+--------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "repair time: 243.190042019\n",
      "\n",
      "Total time: 1250.32977939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        session.ds_repair()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('repair time: '+str(d)+'\\n')\n",
    "        fx.write('repair time: '+str(d)+'\\n')\n",
    "        print 'repair time: '+str(d)+'\\n'\n",
    "\n",
    "        holo_obj.logger.info('Total time: ' + str(sum(list_time)) + '\\n')\n",
    "        fx.write('Total time: ' + str(sum(list_time)) + '\\n')\n",
    "        print 'Total time: ' + str(sum(list_time)) + '\\n'\n",
    "\n",
    "        fx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
