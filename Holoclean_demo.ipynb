{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Step-by-Step Guide to Holoclean example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noisy and erroneous data is a major bottleneck in analytics. Data cleaning and repairing account for about 60% of the work of data scientists. To address this bottleneck, we recently introduced HoloClean, a semi-automated data repairing framework that relies on statistical learning and inference to repair errors in structured data. In HoloClean, we build upon the paradigm of weak supervision and demonstrate how to leverage diverse signals, including user-defined heuristic rules (such as generalized data integrity constraints) and external dictionaries, to repair erroneous data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, we walk through the process of implementing Holoclean, by creating a simple end-to-end example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import all the module from Holoclean that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "from holoclean.errordetection.errordetector import ErrorDetectors\n",
    "from holoclean.featurization.featurizer import SignalInit, SignalCooccur, SignalDC\n",
    "from holoclean.featurization.featurizer import Featurizer\n",
    "from holoclean.learning.softmax import SoftMax\n",
    "from holoclean.learning.accuracy import Accuracy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Initialization\n",
    "In this part, we create the Holoclean and Session object that we will use for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda/envs/python2.7/lib/python2.7/site-packages/sqlalchemy/dialects/mysql/base.py:1576: Warning: '@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\n",
      "  cursor.execute('SELECT @@tx_isolation')\n"
     ]
    }
   ],
   "source": [
    "holo_obj = HoloClean()\n",
    "session = Session(\"Session\", holo_obj)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input and DC from file\n",
    "Test data and the Denial Constraints will be read using the Session's ingestor.\n",
    "After ingesting the test data will be loaded into MySQL tables along with entries in the a metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for ingesting file: 9.41983699799\n",
      "\n",
      "Init table\n",
      "+-----+---+---+---+---+---+\n",
      "|index|  A|  B|  C|  D|  E|\n",
      "+-----+---+---+---+---+---+\n",
      "|    1|  p|  w|  f|  n|  r|\n",
      "|    2|  p|  z|  f|  k|  r|\n",
      "|    3|  u|  y|  m|  n|  r|\n",
      "+-----+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fx = open('execution_time.txt', 'w')\n",
    "# list_time = []\n",
    "# start_time = t()\n",
    "t0 = time.time()\n",
    "#session.ingest_dataset(\"test/inputDatabase.csv\")\n",
    "session.ingest_dataset(\"test/test.csv\")\n",
    "# session.ingest_dataset(\"test/test1.csv\")\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1 - t0\n",
    "fx.write('time for ingesting file: ' + str(total) + '\\n')\n",
    "print 'time for ingesting file: ' + str(total) + '\\n'\n",
    "#session.denial_constraints(\"test/inputConstraint.txt\")\n",
    "session.denial_constraints(\"test/dc1.txt\")\n",
    "# session.denial_constraints(\"test/dc2.txt\")\n",
    "\n",
    "print 'Init table'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Init\", session.dataset)\n",
    "#sql.select('index','ProviderNumber','HospitalName', 'Address1').show()\n",
    "\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection\n",
    "In this part, we create the error detection. The output of this part is the C_dk table that contains all the noisy cells and the C_Clean table that contains the clean cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT table1.index as ind,table2.index as                indexT2 FROM df table1,df table2 WHERE (table1.A=table2.A AND table1.B<>table2.B)\n",
      "SELECT table1.index as ind,table2.index as                indexT2 FROM df table1,df table2 WHERE (table1.C=table2.C AND table1.D<>table2.D)\n",
      "error dectection time: 45.7984521389\n",
      "\n"
     ]
    }
   ],
   "source": [
    " t0 = time.time()\n",
    "err_detector = ErrorDetectors(session.Denial_constraints, holo_obj.dataengine,\n",
    "                             holo_obj.spark_session, session.dataset)\n",
    "session.add_error_detector(err_detector)\n",
    "session.ds_detect_errors()\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "holo_obj.logger.info('error dectection time: '+str(total)+'\\n')\n",
    "fx.write('error dectection time: '+str(total)+'\\n')\n",
    "print 'error dectection time: '+str(total)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Pruning\n",
    "In this part, we prune the domain. The output of this part is the possible_values tables that contains all the possible values for each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain pruning time: 4.60110998154\n",
      "\n",
      "Possible_values_dk\n",
      "+---+---+---------+--------+--------+---------+\n",
      "|vid|tid|attr_name|attr_val|observed|domain_id|\n",
      "+---+---+---------+--------+--------+---------+\n",
      "|  1|  3|        A|       p|       0|        1|\n",
      "|  3|  3|        C|       m|       1|        1|\n",
      "|  2|  3|        B|       y|       1|        1|\n",
      "|  3|  3|        C|       f|       0|        2|\n",
      "|  4|  3|        D|       n|       1|        1|\n",
      "|  1|  3|        A|       u|       1|        2|\n",
      "+---+---+---------+--------+--------+---------+\n",
      "\n",
      "Possible values dk\n",
      "+---+---+---------+--------+--------+---------+\n",
      "|vid|tid|attr_name|attr_val|observed|domain_id|\n",
      "+---+---+---------+--------+--------+---------+\n",
      "|  6|  2|        B|       z|       1|        1|\n",
      "|  4|  1|        D|       n|       1|        1|\n",
      "|  1|  1|        A|       p|       1|        1|\n",
      "|  5|  2|        A|       p|       1|        1|\n",
      "|  7|  2|        C|       f|       1|        1|\n",
      "|  2|  1|        B|       w|       1|        1|\n",
      "|  8|  2|        D|       k|       1|        1|\n",
      "|  3|  1|        C|       f|       1|        1|\n",
      "|  8|  2|        D|       n|       0|        2|\n",
      "+---+---+---------+--------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "pruning_threshold = 0.5\n",
    "session.ds_domain_pruning(pruning_threshold)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "holo_obj.logger.info('domain pruning time: '+str(total)+'\\n')\n",
    "fx.write('domain pruning time: '+str(total)+'\\n')\n",
    "print 'domain pruning time: '+str(total)+'\\n'\n",
    "\n",
    "print 'Possible_values_dk'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Possible_values_clean\", session.dataset)\n",
    "sql.show()\n",
    "\n",
    "print 'Possible values dk'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Possible_values_dk\", session.dataset)\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we implement the featurization module of holoclean. We choose the signals that we want to use and the output of this part is the featurization table that contains the factors that we will use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Signal Time: 0.000380992889404\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "initial_value_signal = SignalInit(session.Denial_constraints, holo_obj.dataengine,\n",
    "                              session.dataset)\n",
    "session.add_featurizer(initial_value_signal )\n",
    "statistics_signal = SignalCooccur(session.Denial_constraints, holo_obj.dataengine,\n",
    "                              session.dataset )\n",
    "session.add_featurizer(statistics_signal)\n",
    "dc_signal = SignalDC(session.Denial_constraints, holo_obj.dataengine, session.dataset,\n",
    "                 holo_obj.spark_session)\n",
    "session.add_featurizer(dc_signal)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print \"Feature Signal Time:\", total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the signals that we choose in the previous step. The output of this part is the featurization table that contains the factors that we will use in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Feature Threads\n",
      "adding a 0.312334060669 \n",
      "Creating parallel queries\n",
      "SignalInit\n",
      "done adding  SignalInit   0.00309801101685\n",
      "adding a  SignalCooccur\n",
      "0.0202610492706\n",
      "Starting threads\n",
      "Thread-7  Query Started \n",
      "Thread-7  Query Execution time:  0.880417823792\n",
      "done adding  SignalCooccur   Thread-81.23641395569 \n",
      " Query Started adding a \n",
      " SignalDC\n",
      "Thread-8  Query Execution time:  0.121952056885\n",
      "done adding  SignalDC Thread-8  Thread-6  Query Started  0.949510097504\n",
      " Query Started Thread-9\n",
      "Thread-7\n",
      "  Query Started  \n",
      " Query Started \n",
      "Thread-8  Query Execution time:  0.00944209098816\n",
      "Thread-9  Query Execution time:  0.00940608978271\n",
      "Thread-7  Query Execution time:  0.0745539665222\n",
      "Thread-6  Query Execution time:  0.099592924118Total Featurization Queries time Before Union: \n",
      "\n",
      "2.29448390007\n",
      " Select * from 606022807473_Thread_6_clean UNION Select * from 606022807473_Thread_7_clean UNION Select * from 606022807473_Thread_8_clean UNION Select * from 606022807473_Thread_9_clean \n",
      "Union Time: \n",
      "0.0439219474792\n",
      "Dimension time:  0.467075109482\n",
      "featurization time: 3.11942887306\n",
      "\n",
      "Feature table clean\n",
      "+---+------------+-------+-----+\n",
      "|vid|assigned_val|feature|count|\n",
      "+---+------------+-------+-----+\n",
      "|  3|           2|     14|    1|\n",
      "|  3|           1|      1|    1|\n",
      "|  2|           1|      1|    1|\n",
      "|  4|           1|      1|    1|\n",
      "|  1|           2|      1|    1|\n",
      "|  1|           1|     12|    2|\n",
      "|  3|           1|      9|    1|\n",
      "|  2|           1|      9|    1|\n",
      "|  4|           1|      9|    1|\n",
      "|  1|           2|      9|    1|\n",
      "|  3|           1|      8|    1|\n",
      "|  4|           1|      8|    1|\n",
      "|  1|           2|      8|    1|\n",
      "|  2|           1|      5|    1|\n",
      "|  4|           1|      5|    1|\n",
      "|  1|           2|      5|    1|\n",
      "|  3|           1|      3|    1|\n",
      "|  2|           1|      3|    1|\n",
      "|  4|           1|      3|    1|\n",
      "|  3|           1|     10|    1|\n",
      "+---+------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "session.ds_featurize()\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1 - t0\n",
    "\n",
    "holo_obj.logger.info('featurization time: '+str(total)+'\\n')\n",
    "fx.write('featurization time: '+str(total)+'\\n')\n",
    "print 'featurization time: '+str(total)+'\\n'\n",
    "\n",
    "print 'Feature table clean'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Feature_clean\", session.dataset)\n",
    "sql.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Learning\n",
    "We create the X-tensor from the feature_clean table and run softmax on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00  0.0000e+00\n",
      " 0.0000e+00 -1.0000e+07\n",
      "[torch.FloatTensor of size 4x2]\n",
      "\n",
      "Variable containing:\n",
      " 0.0245  0.9755\n",
      " 1.0000  0.0000\n",
      " 0.9363  0.0637\n",
      " 1.0000  0.0000\n",
      "[torch.FloatTensor of size 4x2]\n",
      "\n",
      "time for training model: 0.261505842209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "soft = SoftMax(holo_obj.dataengine, session.dataset, holo_obj.spark_session)\n",
    "\n",
    "print(soft.logreg())\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "\n",
    "fx.write('time for training model: '+str(total)+'\\n')\n",
    "print 'time for training model: '+str(total)+'\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use the new weight, to learn the probabilities for each value for the cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Feature Threads\n",
      "adding a 0.501136064529 SignalInit\n",
      "\n",
      "Creating parallel queries\n",
      "done adding  SignalInit   0.00367403030396\n",
      "adding a  SignalCooccur\n",
      "0.018905878067\n",
      "Starting threads\n",
      "Thread-12  Query Started \n",
      "Thread-12  Query Execution time:  0.912790060043\n",
      "done adding  SignalCooccur   1.71454310417\n",
      "adding a  SignalDC\n",
      "Thread-13  Query Started \n",
      "Thread-13  Query Execution time:  0.138799905777\n",
      "done adding  SignalDC   0.484138965607\n",
      "Thread-14  Query Started Thread-13\n",
      "  Query Started \n",
      "Thread-12  Query Started \n",
      "Thread-11  Query Started \n",
      "Thread-13  Query Execution time:  0.104687929153\n",
      "Thread-14  Query Execution time:  Thread-110.138060092926 \n",
      " Query Execution time:  0.137963056564\n",
      "Thread-12  Query Execution time:  0.238415002823\n",
      "Total Featurization Queries time Before Union: \n",
      "2.44323992729\n",
      " Select * from 606022807473_Thread_11_dk UNION Select * from 606022807473_Thread_12_dk UNION Select * from 606022807473_Thread_13_dk UNION Select * from 606022807473_Thread_14_dk \n",
      "Union Time: \n",
      "0.124446868896\n",
      "Dimension time:  0.527009010315\n",
      "time for test featurization: 3.59849286079\n",
      "\n",
      "Feature table dk\n",
      "+---+------------+-------+-----+\n",
      "|vid|assigned_val|feature|count|\n",
      "+---+------------+-------+-----+\n",
      "|  1|           1|     12|    1|\n",
      "|  5|           1|     12|    1|\n",
      "|  6|           1|      1|    1|\n",
      "|  4|           1|      1|    1|\n",
      "|  1|           1|      1|    1|\n",
      "|  5|           1|      1|    1|\n",
      "|  7|           1|      1|    1|\n",
      "|  2|           1|      1|    1|\n",
      "|  8|           1|      1|    1|\n",
      "|  3|           1|      1|    1|\n",
      "|  2|           1|     13|    1|\n",
      "|  6|           1|     13|    1|\n",
      "|  5|           1|      7|    1|\n",
      "|  7|           1|      7|    1|\n",
      "|  8|           1|      7|    1|\n",
      "|  4|           1|      2|    1|\n",
      "|  2|           1|      2|    1|\n",
      "|  3|           1|      2|    1|\n",
      "|  6|           1|      2|    1|\n",
      "|  7|           1|      2|    1|\n",
      "+---+------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00 -1.0000e+07\n",
      " 0.0000e+00  0.0000e+00\n",
      "[torch.FloatTensor of size 8x2]\n",
      "\n",
      "Variable containing:\n",
      " 1.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 1.0000  0.0000\n",
      " 0.1358  0.8642\n",
      "[torch.FloatTensor of size 8x2]\n",
      "\n",
      "time for inference:  0.070100069046\n",
      "Inferred values for dk cells\n",
      "+------------------+---+---------+--------+---+---------+\n",
      "|       probability|vid|attr_name|attr_val|tid|domain_id|\n",
      "+------------------+---+---------+--------+---+---------+\n",
      "|               1.0|  6|        B|       z|  2|        1|\n",
      "|               1.0|  3|        C|       f|  1|        1|\n",
      "|               1.0|  5|        A|       p|  2|        1|\n",
      "|               1.0|  4|        D|       n|  1|        1|\n",
      "|               1.0|  2|        B|       w|  1|        1|\n",
      "|               1.0|  7|        C|       f|  2|        1|\n",
      "|               1.0|  1|        A|       p|  1|        1|\n",
      "|0.8641629219055176|  8|        D|       n|  2|        2|\n",
      "+------------------+---+---------+--------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "session.ds_featurize(0)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "fx.write('time for test featurization: ' + str(total) + '\\n')\n",
    "print 'time for test featurization: ' + str(total) + '\\n'\n",
    "\n",
    "\n",
    "print 'Feature table dk'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Feature_dk\", session.dataset)\n",
    "sql.show()\n",
    "\n",
    "t0 = time.time()\n",
    "Y = soft.predict(soft.model, soft.setuptrainingX(), soft.setupMask(0))\n",
    "print(Y)\n",
    "t1 = time.time()\n",
    "total = t1 - t0\n",
    "print 'time for inference: ', total\n",
    "soft.save_Y_to_db(Y)\n",
    "\n",
    "print 'Inferred values for dk cells'\n",
    "sql = holo_obj.dataengine.get_table_to_dataframe(\"Inferred_values\", session.dataset)\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
