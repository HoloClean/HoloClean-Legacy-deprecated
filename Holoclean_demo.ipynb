{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLOCLEAN DEMO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "from holoclean.errordetection.errordetector import ErrorDetectors\n",
    "from holoclean.featurization.featurizer import SignalInit, SignalCooccur, SignalDC\n",
    "from holoclean.learning.accuracy import Accuracy\n",
    "from time import time as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Holoclean demo\n",
    "Create HoloClean object and Session.\n",
    "The HoloClean object will log all info for the test.\n",
    "Session will be used to ingest data from input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing started :1515439092.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda/envs/python2.7/lib/python2.7/site-packages/sqlalchemy/dialects/mysql/base.py:1576: Warning: '@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\n",
      "  cursor.execute('SELECT @@tx_isolation')\n"
     ]
    }
   ],
   "source": [
    "        holo_obj = HoloClean()\n",
    "        session = Session(\"Session\", holo_obj) \n",
    "        print \"Testing started :\"+str(t())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input and DC from file\n",
    "Test data and the Denial Constraints will be read using the Session's ingestor.\n",
    "After ingesting the test data will be loaded into MySQL tables along with entries in the a metadata table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingest csv time: 7.58988213539\n",
      "\n",
      "read denial constraints time: 0.0154159069061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        fx = open('execution_time.txt', 'w')\n",
    "        list_time = []\n",
    "        start_time = t()\n",
    "        \n",
    "        #session.ingest_dataset(\"test/inputDatabase.csv\")\n",
    "        session.ingest_dataset(\"test/test.csv\")\n",
    "        d = t()-start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('ingest csv time: '+str(d)+'\\n')\n",
    "        fx.write('ingest csv time: '+str(d)+'\\n')\n",
    "        print 'ingest csv time: '+str(d)+'\\n'\n",
    "        \n",
    "        start_time = t()\n",
    "        \n",
    "        #session.denial_constraints(\"test/inputConstraint.txt\")\n",
    "        session.denial_constraints(\"test/dc1.txt\")\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('read denial constraints time: '+str(d)+'\\n')\n",
    "        fx.write('read denial constraints time: '+str(d)+'\\n')\n",
    "        print 'read denial constraints time: '+str(d)+'\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection\n",
    "Using the Denial Constraints read through the ingestor, apply Error Detection on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error dectection time: 26.1363401413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        err_detector = ErrorDetectors(session.Denial_constraints, holo_obj.dataengine,\n",
    "                                      holo_obj.spark_session, session.dataset)\n",
    "        session.add_error_detector(err_detector)\n",
    "        session.ds_detect_errors()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('error dectection time: '+str(d)+'\\n')\n",
    "        fx.write('error dectection time: '+str(d)+'\\n')\n",
    "        print 'error dectection time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Pruning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain pruning time: 1.4309990406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        pruning_threshold = 0.5\n",
    "        session.ds_domain_pruning(pruning_threshold)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('domain pruning time: '+str(d)+'\\n')\n",
    "        fx.write('domain pruning time: '+str(d)+'\\n')\n",
    "        print 'domain pruning time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Value Signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init signal time: 0.000114917755127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        start_time1 = t()\n",
    "        initial_value_signal = SignalInit(session.Denial_constraints, holo_obj.dataengine,\n",
    "                                          session.dataset)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('init signal time: '+str(d)+'\\n')\n",
    "        fx.write('init signal time: '+str(d)+'\\n')\n",
    "        print 'init signal time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-occurence Signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooccur signal time: 0.00043511390686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        session.add_featurizer(initial_value_signal)\n",
    "        statistics_signal = SignalCooccur(session.Denial_constraints, holo_obj.dataengine,\n",
    "                                          session.dataset)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('cooccur signal time: '+str(d)+'\\n')\n",
    "        fx.write('cooccur signal time: '+str(d)+'\\n')\n",
    "        print 'cooccur signal time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC Featurization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dc signal time: 0.00028395652771\n",
      "\n",
      "dc featurize time: 8.39233398438e-05\n",
      "\n",
      "INSERT INTO 00590556366891_Feature_temp SELECT * FROM (  (SELECT  @p := @p + 1 AS var_index,            init_flat.tid AS rv_index,            init_flat.attr_name AS rv_attr,            init_flat.attr_val AS assigned_val,            concat('Init=',init_flat.attr_val ) AS feature,            'init' AS TYPE,            '      ' AS weight_id            FROM 00590556366891_Init_flat AS init_flat WHERE (init_flat.attr_name = 'A' OR init_flat.attr_name = 'B'))as T_0);\n",
      "INSERT INTO 00590556366891_Feature_temp SELECT * FROM (  (SELECT DISTINCT @p := @p + 1 AS var_index,cooccur.tid_first AS rv_index,cooccur.attr_first AS rv_attr,cooccur.val_first AS assigned_val,CONCAT (cooccur.attr_second , '=' , cooccur.val_second ) AS feature,'cooccur' AS TYPE,'        ' AS weight_id FROM 00590556366891_Init_flat_join AS cooccur WHERE (cooccur.attr_first = 'A' OR cooccur.attr_first = 'B'))as T_1);\n",
      "INSERT INTO 00590556366891_Feature_temp SELECT * FROM (SELECT @p := @p + 1 AS var_index,possible_table.tid AS rv_index,possible_table.attr_name AS rv_attr,possible_table.attr_val AS assigned_val,CONCAT ( table1.second_index ,':', 'table1.first_A=table1.second_A AND table1.first_B<>table1.second_B') AS feature,'FD' AS TYPE,'       ' AS weight_id  FROM (SELECT * FROM 00590556366891_Init_join AS table1 WHERE table1.first_B<>table1.second_B) AS table1, (SELECT * FROM 00590556366891_Possible_values AS possible_table WHERE possible_table.attr_name= 'A' ) AS possible_table WHERE ((possible_table.attr_val=table1.second_A) AND possible_table.tid=table1.first_index))AS T_2;\n",
      "INSERT INTO 00590556366891_Feature_temp SELECT * FROM (SELECT @p := @p + 1 AS var_index,possible_table.tid AS rv_index,possible_table.attr_name AS rv_attr,possible_table.attr_val AS assigned_val,CONCAT ( table1.second_index ,':', 'table1.first_A=table1.second_A AND table1.first_B<>table1.second_B') AS feature,'FD' AS TYPE,'       ' AS weight_id  FROM (SELECT * FROM 00590556366891_Init_join AS table1 WHERE table1.first_A=table1.second_A) AS table1, (SELECT * FROM 00590556366891_Possible_values AS possible_table WHERE possible_table.attr_name= 'B' ) AS possible_table WHERE ((possible_table.attr_val<>table1.second_B) AND possible_table.tid=table1.first_index))AS T_3;\n",
      "adding weight_id to feature table...\n",
      "adding weight_id to feature table is finished\n",
      "total featurization time: 2.4924788475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        session.add_featurizer(statistics_signal)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('dc signal time: '+str(d)+'\\n')\n",
    "        fx.write('dc signal time: '+str(d)+'\\n')\n",
    "        print 'dc signal time: '+str(d)+'\\n'\n",
    "        start_time = t()\n",
    "        dc_signal = SignalDC(session.Denial_constraints, holo_obj.dataengine, session.dataset)\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('dc featurize time: '+str(d)+'\\n')\n",
    "        fx.write('dc featurize time: '+str(d)+'\\n')\n",
    "        print 'dc featurize time: '+str(d)+'\\n'\n",
    "        session.add_featurizer(dc_signal)\n",
    "        session.ds_featurize()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('total featurization time: '+str(d)+'\\n')\n",
    "        fx.write('total featurization time: '+str(d)+'\\n')\n",
    "        print 'total featurization time: '+str(d)+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbskull is starting\n",
      "wrapper is starting\n",
      "wrapper is finished\n",
      "1\n",
      "numbskull is finished\n",
      "adding weight is finished is finished\n",
      "numbskull time: 9.37386894226\n",
      "\n",
      "starting repairs\n",
      "repairs are finished\n",
      "repair time: 1.10969305038\n",
      "\n",
      "Total time: 48.1495959759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "        start_time = t()\n",
    "        session._numskull()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('numbskull time: '+str(d)+'\\n')\n",
    "        fx.write('numbskull time: '+str(d)+'\\n')\n",
    "        print 'numbskull time: '+str(d)+'\\n'\n",
    "        start_time = t()\n",
    "        session.ds_repair()\n",
    "        d = t() - start_time\n",
    "        list_time.append(d)\n",
    "        holo_obj.logger.info('repair time: '+str(d)+'\\n')\n",
    "        fx.write('repair time: '+str(d)+'\\n')\n",
    "        print 'repair time: '+str(d)+'\\n'\n",
    "\n",
    "        holo_obj.logger.info('Total time: ' + str(sum(list_time)) + '\\n')\n",
    "        fx.write('Total time: ' + str(sum(list_time)) + '\\n')\n",
    "        print 'Total time: ' + str(sum(list_time)) + '\\n'\n",
    "\n",
    "        fx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
