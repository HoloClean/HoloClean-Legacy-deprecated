{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Custom Error Detectors\n",
    "\n",
    "HoloClean learns to clean data by first splitting it into two categories `clean` and `dont_know` or `dk` for short. It then uses the `clean` set to learn a factor graph. We've provided one kind of error detector, the `DCErrorDetector` which uses Denial Constraints to make these splits. However, HoloClean accepts arbitrary splits through the `ErrorDetector` class.\n",
    "\n",
    "# A `hello world` Example\n",
    "The heart of an error detector is two functions, `get_noisy_cells` and `get_clean_cells`. We are using the hospital dataset from before. We know that some Zip Codes are formatted incorrectly, so we'll write an error detector that gives HoloClean all the erroneous Zip Codes using some simple regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleErrorDetector:\n",
    "    def __init__(self, session):\n",
    "        self.spark_session = session.holo_env.spark_session\n",
    "        self.dataengine = session.holo_env.dataengine\n",
    "        self.dataset = session.dataset\n",
    "    \n",
    "    def get_noisy_cells(self):\n",
    "        '''\n",
    "            well get a spark DataFrame Instance of our Data\n",
    "            and return a new DataFrame with the schema \n",
    "            |ind|attr|\n",
    "            \n",
    "            where ind is the index of our data \n",
    "            and attr is the name of the column \n",
    "            or columns we believe are dirty\n",
    "        '''\n",
    "        spark_data_frame = self.dataengine.get_table_to_dataframe('Init', self.dataset)\n",
    "    \n",
    "        spark_data_frame.createOrReplaceTempView(\"table1\")\n",
    "        query = \"SELECT __ind as ind \"\\\n",
    "                \"FROM table1 \"\\\n",
    "                \"WHERE \"\\\n",
    "                \"ZipCode NOT RLIKE '[0-9]{5}'\"\n",
    "            \n",
    "        result = self.spark_session.sql(query)\n",
    "        attr_frame = self.spark_session.createDataFrame([['ZipCode']], ['attr'])\n",
    "        result = result.crossJoin(attr_frame)\n",
    "        return result\n",
    "                                              \n",
    "                                      \n",
    "        \n",
    "    \n",
    "    def get_clean_cells(self):\n",
    "        '''\n",
    "            The same as before, but now we'll get \n",
    "            reference noisy data in case we need it\n",
    "        '''\n",
    "        spark_data_frame = self.dataengine.get_table_to_dataframe('Init', self.dataset)\n",
    "        \n",
    "        spark_data_frame.createOrReplaceTempView(\"table1\")\n",
    "        query = \"SELECT __ind as ind \"\\\n",
    "                \"FROM table1 \"\\\n",
    "                \"WHERE \"\\\n",
    "                \"ZipCode RLIKE '[0-9]{5}'\"\n",
    "            \n",
    "        result = self.spark_session.sql(query)\n",
    "        attr_frame = self.spark_session.createDataFrame([['ZipCode']], ['attr'])\n",
    "        result = result.crossJoin(attr_frame)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll start up HoloClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda/envs/python2.7/lib/python2.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from holoclean.holoclean import HoloClean, Session\n",
    "\n",
    "holo_obj =  HoloClean(\n",
    "            holoclean_path=\"..\",         # path to holoclean package\n",
    "            verbose=True,\n",
    "            # to limit possible values for training data\n",
    "            pruning_threshold1=0.1,\n",
    "            # to limit possible values for training data to less than k values\n",
    "            pruning_clean_breakoff=6,\n",
    "            # to limit possible values for dirty data (applied after\n",
    "            # Threshold 1)\n",
    "            pruning_threshold2=0,\n",
    "            # to limit possible values for dirty data to less than k values\n",
    "            pruning_dk_breakoff=6,\n",
    "            # learning parameters\n",
    "            learning_iterations=30,\n",
    "            learning_rate=0.001,\n",
    "            batch_size=5\n",
    "        )\n",
    "session = Session(holo_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And ingest the dataset\n",
    "\n",
    "You can review what's happening here in our [Data Loading & Denial Constraints Tutorial](Tutorial_1.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Load Data: 6.77303004265\n",
      "\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|__ind|ProviderNumber|        HospitalName|            Address1|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "|    1|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    2|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    3|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    4|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    5|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    6|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    7|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    8|         10018|CALLAHAN EYE FOUN...|1720 UNIVERSITY BLVD|\n",
      "|    9|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   10|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   11|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   12|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   13|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   14|         1xx19|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   15|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   16|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   17|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   18|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   19|         10019|HELEN KELLER MEMO...|1300 SOUTH MONTGO...|\n",
      "|   20|         10001|SOUTHEAST ALABAMA...|1108 ROSS CLARK C...|\n",
      "+-----+--------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = \"data/hospital_dataset.csv\"\n",
    "\n",
    "denial_constraints = \"data/hospital_constraints.txt\"\n",
    "\n",
    "ground_truth = \"data/groundtruth.csv\"\n",
    "\n",
    "# Ingesting Dataset and Denial Constraints\n",
    "\n",
    "data = session.load_data(dataset)\n",
    "\n",
    "data.select('__ind','ProviderNumber','HospitalName', 'Address1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Your Error Detector to HoloClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Error Detection: 0.957987070084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    We instantiate an ErrorDetector class,\n",
    "    and give it an instance of our\n",
    "    SimpleErrorDetector Object\n",
    "'''\n",
    "err = SimpleErrorDetector(session)\n",
    "#run error detection\n",
    "error_detector_list =[]\n",
    "error_detector_list.append(err)\n",
    "clean, dirty = session.detect_errors(error_detector_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the results\n",
    "\n",
    "The following table will give us all records which are believed to be erroneous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|ind|   attr|\n",
      "+---+-------+\n",
      "| 45|ZipCode|\n",
      "| 64|ZipCode|\n",
      "| 71|ZipCode|\n",
      "| 94|ZipCode|\n",
      "|138|ZipCode|\n",
      "+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dirty.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we view the original dataset, viewing index 45 will confirm our suspicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|__ind|ZipCode|\n",
      "+-----+-------+\n",
      "|   45|  x5957|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data.__ind == 45).select([\"__ind\",\"ZipCode\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
