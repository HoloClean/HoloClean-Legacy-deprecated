{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 4: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brief tutorial explains Holoclean's built-in performance evaluation. At this time, it is a simple process. We input a 'ground truth' dataset with all of the correct values for each cell. This ground truth needs to be created for each dataset that you wish to evaluate Holoclean on. \n",
    "\n",
    "Holoclean then compares its inferred values to the correct values in the ground truth and outputs simple measures of precision and recall. Let's see an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code again for running Holoclean on the hospital dataset. See our [Complete Pipeline Tutorial](Tutorial_2.ipynb) if you haven't already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "from holoclean.holoclean import HoloClean, Session\n",
    "from holoclean.errordetection.sql_dcerrordetector import SqlDCErrorDetection\n",
    "\n",
    "holo = HoloClean(holoclean_path=\"..\")\n",
    "session = Session(holo)\n",
    "\n",
    "data_path = \"data/hospital.csv\"\n",
    "data = session.load_data(data_path)\n",
    "\n",
    "dc_path = \"data/hospital_constraints.txt\"\n",
    "dcs = session.load_denial_constraints(dc_path)\n",
    "\n",
    "\n",
    "detector = SqlDCErrorDetection(session)\n",
    "\n",
    "error_detector_list =[]\n",
    "error_detector_list.append(detector)\n",
    "clean, dirty = session.detect_errors(error_detector_list)\n",
    "\n",
    "repaired = session.repair()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the evaluation as described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have detected 185 errors out of 509 total\n",
      "The top-1 precision  is : 0.999\n",
      "The top-1 recall is : 0.978 over the 185 errors found during error detection\n"
     ]
    }
   ],
   "source": [
    "session.compare_to_truth(\"data/hospital_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform a slightly more sophisticated version of the current evaluation. Instead of checking only Holoclean's most likely value, we can have it check if any of the k most likely values are the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This change is done simply by specifying a parameter when initializing Holoclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have detected 185 errors out of 509 total\n",
      "The top-5 precision  is : 1.000\n",
      "The top-5 recall is : 1.000 over the 185 errors found during error detection\n",
      "The  MAP precision  is : 0.999\n",
      "The MAP recall is : 0.978 over the 185 errors found during error detection\n"
     ]
    }
   ],
   "source": [
    "holo.spark_session.stop()\n",
    "\n",
    "holo_2 = HoloClean(holoclean_path=\"..\", k_inferred = 5)\n",
    "session = Session(holo_2)\n",
    "\n",
    "data = session.load_data(data_path)\n",
    "dcs = session.load_denial_constraints(dc_path)\n",
    "\n",
    "detector = SqlDCErrorDetection(session)\n",
    "\n",
    "error_detector_list =[]\n",
    "error_detector_list.append(detector)\n",
    "clean, dirty = session.detect_errors(error_detector_list)\n",
    "\n",
    "repaired = session.repair()\n",
    "\n",
    "session.compare_to_truth(\"data/hospital_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're working on more sophisticated evaluation techniques, including an interactive evaluator that enables users to self-examine a sample of the inferred values, so stay tuned!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
